import argparse
import os
import shutil
from pathlib import Path
from typing import List

import numpy as np
from PIL import Image
from torch.utils.data import Dataset

class CustomImageToYoloSaver:
    def xyxy_to_xywh(self, box_xyxy: np.ndarray, w: int, h: int) -> np.ndarray:
        if box_xyxy.size == 0:
            return box_xyxy.reshape(0, 4)

        xmin, ymin, xmax, ymax = np.split(box_xyxy, 4, axis=1)
        bw = (xmax - xmin) / w
        bh = (ymax - ymin) / h
        cx = (xmin + xmax) / 2.0 / w
        cy = (ymin + ymax) / 2.0 / h

        xywh = np.concatenate([cx, cy, bw, bh], axis=1)

        np.clip(xywh, 0.0, 1.0, out=xywh)
        return xywh
    
    def save_label_txt(self, txt_path: Path, labels: np.ndarray, boxes_xywh: np.ndarray):
        txt_path.parent.mkdir(parents=True, exist_ok=True)
        if boxes_xywh.size == 0:
            txt_path.write_text("")
            return

        lines = []
        for cls, (cx, cy, bw, bh) in zip(labels.tolist(), boxes_xywh.tolist()):
            lines.append(f"{cls} {cx:.6f} {cy:.6f} {bw:.6f} {bh:.6f}")
        txt_path.write_text("\n".join(lines) + "\n")

    
    def to_uint8_rgb(self, img: np.ndarray) -> np.ndarray:
        if img.dtype == np.uint8:
            out = img
        else:
            arr = img.astype(np.float32, copy=False)
            mx = float(arr.max()) if arr.size else 1.0
            if mx <= 1.0 + 1e-6:
                arr = arr * 255.0
            arr = np.clip(arr, 0.0, 255.0)
            out = arr.astype(np.uint8)
        if out.ndim != 3 or out.shape[2] != 3:
            raise ValueError(f"Expected HxWx3 RGB array, got shape {out.shape}")
        return out
    
    def save_image_from_ram(self, dst_path: Path, img_np: np.ndarray, fmt: str = "JPEG"):
        dst_path.parent.mkdir(parents=True, exist_ok=True)
        img_uint8 = self.to_uint8_rgb(img_np)
        Image.fromarray(img_uint8, mode="RGB").save(dst_path, format=fmt, quality=95, subsampling=2)
    
    def save_split(self, ds: Dataset, split_name: str, out_root: Path):
        img_out_dir = out_root / "images" / split_name
        lbl_out_dir = out_root / "labels" / split_name
        img_out_dir.mkdir(parents=True, exist_ok=True)
        lbl_out_dir.mkdir(parents=True, exist_ok=True)

        n = len(ds)
        empty_cnt = 0
        for i in range(n):
            img_np, tgt = ds[i]

            dst_img_path = img_out_dir / f"{i}.jpg"
            dst_lbl_path = lbl_out_dir / f"{i}.txt"
            self.save_image_from_ram(dst_img_path, img_np, fmt="JPEG")

            h, w = img_np.shape[0], img_np.shape[1]
            boxes_xyxy = tgt["boxes"].astype(np.float32)
            labels = tgt["labels"].astype(np.int64)

            boxes_yolo = self.xyxy_to_xywh(boxes_xyxy, w, h)
            if boxes_yolo.size == 0:
                empty_cnt += 1

            self.save_label_txt(dst_lbl_path, labels, boxes_yolo)

        print(f"[{split_name}] exported {n} images → {img_out_dir}")
        print(f"[{split_name}] empty label files: {empty_cnt}")


    def write_data_yaml(self, out_root: Path, names: List[str]):
        data_yaml = f"""# Auto-generated by save_voc_to_yolo.py
path: {out_root.resolve()}
train: images/train
val: images/val
names:
"""
        for i, n in enumerate(names):
            data_yaml += f"  {i}: {n}\n"

        (out_root / "data.yaml").write_text(data_yaml)
        print(f"[data.yaml] written → {(out_root / 'data.yaml').resolve()}")

    def save(self, labels: list[str], out_root: str, train_ds: Dataset, val_ds: Dataset):
        out_root = Path(out_root).expanduser()
        out_root.mkdir(parents=True, exist_ok=True)

        self.save_split(train_ds, "train", out_root)
        self.save_split(val_ds, "val", out_root)

        self.write_data_yaml(out_root, labels)
        print(f"All done. Dataset saved to: {out_root.resolve()}")




